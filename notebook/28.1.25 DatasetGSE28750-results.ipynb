{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0362b1ac",
   "metadata": {},
   "source": [
    "# Dataset: GSE28750\n",
    "\n",
    "This study applies gene expression biomarkers to distinguish sepsis patients from those with systemic inflammation due to surgery. The goal is to develop a multi-marker diagnostic tool for early sepsis detection, within a clinical environment focused on SIRS differentiation.\n",
    "\n",
    "### Study design:\n",
    "\n",
    "1. Sepsis patients (n=27) met the 1992 Consensus Statement criteria and had microbiological evidence of infection.\n",
    "\n",
    "2. Post-surgical patients (n=38): Blood collected within 24 hours after major surgery.\n",
    "\n",
    "3. Healthy controls (n=20): Hospital staff with no known concurrent illness.\n",
    "\n",
    "\n",
    "Overall Dataset Composition:\n",
    "\n",
    "sepsis_data_GSE28750 -> Sepsis: 10 and Healthy controls: 20. (30 rows and 100 columns)\n",
    "\n",
    "\n",
    "Present genes : 55\n",
    "\n",
    "Missing genes: 0\n",
    "\n",
    "The dataset was already normalized, 55 genes of interest filtered and prepared for random forest test. \n",
    "\n",
    "## Random Forest\n",
    "\n",
    "We applied a random forest test on a dataset (sepsis_data_GSE28750.csv) to evaluate the prediction accuracy based on our 55 genes expression data between sepsis patients and healthy controls.(Rf-samesplit_GSE28750code.R). We ran a random forest 100 times with random splitting data to train and test and calculate the MCC, F1 score, AUC and … for all 100 repeats. (repeated_splits_metrics_GSE28750.csv).\n",
    "\n",
    "Average metrics:\n",
    "Here is the result for making the average of each metric over 100 iterations. (average_metrics_GSE28750.csv)\n",
    "\n",
    "MCC     0.944868329805051\n",
    "F1      0.95\n",
    "AUC     1\n",
    "TPR     0.925\n",
    "TNR     1\n",
    "PPV     1\n",
    "NPV     0.97 \n",
    "\n",
    "\n",
    "## Feature removal test\n",
    "\n",
    "In the next step, we tried to figure out which feature or gene has more impact on MCC results. So we run each 100 time iteration by removing one of the features and calculate all the metrics to realize by removing which one we can see more drop in MCC value. (feature_removal_results_GSE28750.csv)\n",
    "\n",
    "\n",
    "\n",
    "Top Features (**SOCS3.3, C3AR1, S100A9, S100A8,PLAUR.1**):\n",
    "These are likely key biomarkers and should be prioritized in biological interpretation and downstream analysis. They are central to the model's predictions and could be explored further for biological relevance.\n",
    "\n",
    "Bottom Features (**ARG1, SOCS3, P2RX7, ARG1.1, OLFM4**):\n",
    "These features might not be crucial for prediction in this context. Consider removing them to simplify the model or explore their redundancy with other features.\n",
    "\n",
    "## Sanity check\n",
    "\n",
    "Noise is artificially introduced into the dataset, and the model's performance metrics are observed as the noise level increases.(sanity_check_results_GSE28750.csv)\n",
    "\n",
    "Noise Level 0: Represents the original data with no added noise (baseline performance).\n",
    "\n",
    "Noise Levels 10–50: Increasing levels of noise are added to the input data, simulating scenarios with reduced data quality or signal interference.\n",
    "\n",
    "\n",
    "We can see Performance drops significantly between 20% and 30% noise, suggesting that noise at this level corrupts important features.\n",
    "A partial recovery at 40% noise indicates that the model may be adapting to randomness, but performance degrades again at 50% noise.\n",
    "AUC remains stable, meaning that the model maintains ranking ability but suffers in absolute classification accuracy as shown by F1 and MCC.\n",
    "\n",
    "\n",
    "But the problem here is again the small size of the dataset and the imbalance in the number of sepsis and healthy ones.\n",
    "\n",
    "\n",
    "Confusion Matrix and Statistics\n",
    "\n",
    "          Reference\n",
    "Prediction HEALTHY SEPSIS\n",
    "   HEALTHY       4      0\n",
    "   SEPSIS        0      2\n",
    "                                     \n",
    "               Accuracy : 1          \n",
    "                 95% CI : (0.5407, 1)\n",
    "    No Information Rate : 0.6667     \n",
    "    P-Value [Acc > NIR] : 0.08779    \n",
    "                                     \n",
    "                  Kappa : 1          \n",
    "                                     \n",
    " Mcnemar's Test P-Value : NA         \n",
    "                                     \n",
    "            Sensitivity : 1.0000     \n",
    "            Specificity : 1.0000     \n",
    "         Pos Pred Value : 1.0000     \n",
    "         Neg Pred Value : 1.0000     \n",
    "             Prevalence : 0.3333     \n",
    "         Detection Rate : 0.3333     \n",
    "   Detection Prevalence : 0.3333     \n",
    "      Balanced Accuracy : 1.0000     \n",
    "                                     \n",
    "       'Positive' Class : SEPSIS     \n",
    "                                     \n",
    "> table(data$Label)\n",
    "\n",
    "HEALTHY  SEPSIS \n",
    "     20      10 \n",
    "> table(train_data$Label)\n",
    "\n",
    "HEALTHY  SEPSIS \n",
    "     16       8 \n",
    "> table(test_data$Label)\n",
    "\n",
    "HEALTHY  SEPSIS \n",
    "      4       2\n",
    "\n",
    "\n",
    "--------------------\n",
    "\n",
    "So we just perform random forest again using SMOTE resampling to solve the imbalancing issue.\n",
    "Random forest and resampling by SMOTE:\n",
    "\n",
    "## Random forest\n",
    "We applied a random forest test on a dataset (sepsis_data_GSE28750.csv) and used SMOTE resampling to evaluate the prediction accuracy based on our 55 genes expression data between sepsis patients and healthy controls.(RF_samesplit_SMOTE_GSE28750code.R). We ran a random forest 100 times with random splitting data to train and test and calculate the MCC, F1 score, AUC and … for all 100 repeats. (repeated_splits_SMOTE_GSE28750.csv).\n",
    "\n",
    "## Average metrics\n",
    "Here is the result for making the average of each metric over 100 iterations. (average_metrics_GSE28750.csv)\n",
    "\n",
    "MCC    0.949570108523704\n",
    "F1     0.953333333333333\n",
    "AUC    0.99\n",
    "TPR    0.935\n",
    "TNR    0.99\n",
    "PPV    0.99\n",
    "NPV    0.968\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "table(data$Label)\n",
    "\n",
    "HEALTHY  SEPSIS \n",
    "     20      10 \n",
    "> table(train_data$Label)\n",
    "\n",
    "HEALTHY  SEPSIS \n",
    "     16       8 \n",
    "> table(smote_train_data$Label)\n",
    "\n",
    "HEALTHY  SEPSIS \n",
    "     16      16 \n",
    "> table(test_data$Label)\n",
    "\n",
    "HEALTHY  SEPSIS \n",
    "      4       2\n",
    "\n",
    "\n",
    "We can see after using SMOTE the train data that we used has become balanced.\n",
    "\n",
    "\n",
    "## Feature removal test\n",
    "\n",
    "In the next step, we tried to figure out which feature or gene has more impact on MCC results. So we run each 100 time iteration by removing one of the features and calculate all the metrics to realize by removing which one we can see more drop in MCC value. (feature_removal_results_GSE28750.csv)\n",
    "\n",
    "\n",
    "Top Features (**LBP, NLRP3, BCL2.3, S100A9**):These are likely key biomarkers and should be prioritized in biological interpretation and downstream analysis. They are central to the model's predictions and could be explored further for biological relevance.\n",
    "\n",
    "Bottom Features (**ARG1, BCL2.1, NLRP3.1, ARG1.1**):These features might not be crucial for prediction in this context. Consider removing them to simplify the model or explore their redundancy with other features.\n",
    "\n",
    "## Sanity check\n",
    "\n",
    "Noise is artificially introduced into the dataset, and the model's performance metrics are observed as the noise level increases.(sanity_check_results_GSE28750.csv)\n",
    "Noise Level 0: Represents the original data with no added noise (baseline performance).\n",
    "Noise Levels 10–50: Increasing levels of noise are added to the input data, simulating scenarios with reduced data quality or signal interference.\n",
    "\n",
    "\n",
    "We can see Performance drops significantly between 10% and 20% noise, suggesting that noise at this level corrupts important features.\n",
    "A partial recovery at 30% noise indicates that the model may be adapting to randomness, but performance degrades again at 50% noise.\n",
    "AUC remains stable, meaning that the model maintains ranking ability but suffers in absolute classification accuracy as shown by F1 and MCC.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
